{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de una Red neuronal Pequeña.\n",
    "Código Basado en https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "from random import seed, random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una red neuronal es una función universal con  3 tipos de capas: capa de entrada, capas intermedia capa de salida. \n",
    "\n",
    "* Un problema es que la derivada no se puede calcular directamente. Desde la la capa de salida, solo se tiene acceso a las derivadas parciales de la capa antecesora inmediata.\n",
    "\n",
    "* Por lo tanto se requiere un algoritmo especial para calcular la derivada basada en la regla de la cadena de cálculo. \n",
    "\n",
    "* Esta indica que si se tienen funciones anidadas: $y=g(x), z = f(y)$ o bien $z = f(g(x))$, una manera de resolver esta anidación es aplicando la regla de la cadena. Ejemplo:\n",
    "\n",
    "$$\\frac{d z}{d x} = \\frac{dz}{dy} \\frac{dy}{dx} $$\n",
    "\n",
    "* El algoritmo de **Propagación hacia atrás** (Backpropagation, BP), es un algoritmo de entrenamiento supervisado permite calcular la derivada de una red neuronal y por lo tanto actualizar los pesos de todas las capas intermedias.\n",
    "\n",
    "* Por lo tanto describiremos un código de una red neuronal con fines didácticos. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo Red neuronal multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inicializando la red**\n",
    "\n",
    "initialize_network recibe el tamaño del vector de entrada, el número de capas ocultas y el numero de capas de salida.\n",
    "\n",
    "Si inicializamos initialize_network(3, 2, 2), tendremos 2 conjuntos de 3+1 pesos considerando el *bias* para la primera capa que asocia cada entrada de $[x_0,x_1,x_0]$ con cada neurona intermedia. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capa de entrada: [{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "\n",
    "seed(1)\n",
    "network = initialize_network(2, 2, 1)\n",
    "\n",
    "print(\"capa de entrada:\", network[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propagación hacia adelante** (Forwad propagation): salida de la red neuronal dada una entrada $\\mathbf{x}$\n",
    "\n",
    "Es la función que nos permite utilizar la red neuronal para hacer clasificación. La entrada se va procesando a través de las capas hasta obtener una salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activación de la neurona**\n",
    "\n",
    "Es el cálculo de una regresión lineal de la forma \n",
    "\n",
    "$$y = \\mathbf{x}\\mathbf{w}^T + w_0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calcular activacion de la neurona por una entrada\n",
    "def activate(weights, inputs):\n",
    "    # W*X+w_0\n",
    "    \n",
    "    #bias: w_0\n",
    "    activation = weights[-1]\n",
    "    \n",
    "    #calcular w_0 + W*X\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "        \n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transferencia de la neurona**\n",
    "\n",
    "Existen muchas funciones de transferencia como relu, tanh identidad, pero una de las mas utilizadas es la función sigmoide con forma de s o también llamada curva logística. Tiene la forma:\n",
    "\n",
    "$$\\hat{z} = \\text{sigm}(y) = 1/(1+e^{-y}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neurona\n",
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + exp(-activation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivada de transferencia hacia atrás de las capas intermedias**\n",
    "\n",
    "Esta derivada es solo una parte de la derivda de toda la red neuronal que se hace en forma encadenada. \n",
    "\n",
    "$$ \\frac{\\partial \\hat{z}}{\\partial y} = \\hat{z} (1-\\hat{z} )   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta es la derivada de la función sigmoide\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propagación hacia adelante**\n",
    "\n",
    "Es la red neuronal en funcionamiento. Recibe una entrada $\\mathbf{x_i}$ y regresa una salida $y_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagación hacia adelante\n",
    "def forward_propagate(network, inputs):\n",
    "\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8138219506313304]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_propagate(network,[1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349],\n",
       "  'output': 0.8138219506313304}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propagación hacia atrás del error**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# Propaga el error hacia atrás y lo va guardando en la estructura de la red\n",
    "def backward_propagate_error(network, expected):\n",
    "    \n",
    "    #comenzamos con la capa de salida\n",
    "    for i in reversed(range(len(network))):\n",
    "        \n",
    "        # por cada capa de la red asignada a layer\n",
    "        layer = network[i]\n",
    "        \n",
    "        #el tamaño de la capa es equivalente al numero de neuronas en la capa\n",
    "        n_neuronas = len(layer)\n",
    "        \n",
    "        #inicializamos error\n",
    "        errors = list()\n",
    "        \n",
    "        # la primera vez calculamos sobre la ultima capa que es a la que tenemos acceso en un inicio\n",
    "        if i == len(network)-1:\n",
    "            \n",
    "            # por cada neurona de la capa hacer:\n",
    "            for j in range(n_neuronas):\n",
    "            \n",
    "                neuron = layer[j]\n",
    "\n",
    "                yhat = neuron['output']\n",
    "                y = expected[j]\n",
    "            \n",
    "                #esta es la derivada de la función de costo (o error) basada en la log verosimilitud\n",
    "                # Aqui comienza la transferencia\n",
    "                derivada_error = (yhat-y)/((yhat-1)*yhat)\n",
    "                errors.append(derivada_error) \n",
    "        \n",
    "        else:\n",
    "            #aqui son las capas restantes hacia atrás donde propagamos el error\n",
    "            \n",
    "            for j in range(n_neuronas):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    \n",
    "                    #son los pesos de las entradas de la ultima capa\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                    \n",
    "                errors.append(error)\n",
    "                \n",
    "        #aqui guardamos todos los delta asociada a cada neurona de cada capa\n",
    "        for j in range(n_neuronas):\n",
    "            neuron = layer[j]\n",
    "            \n",
    "            #el error magnifica la derivada\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_propagate_error(network,[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614],\n",
       "   'output': 0.9864519743186091,\n",
       "   'delta': 0.0016212755200530635},\n",
       "  {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381],\n",
       "   'output': 0.9362134079958969,\n",
       "   'delta': 0.008769148617603043}],\n",
       " [{'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349],\n",
       "   'output': 0.8138219506313304,\n",
       "   'delta': 0.18617804936866958}]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actualizar pesos con el error**\n",
    "\n",
    "Se recibe la red con los deltas, y un vector de entrada $row$ y la tasa de aprendizaje $l_rate$ asignada por el usuario la cual especifica en porcentaje de actualización que queremos para los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizar los pesos de la red \n",
    "def update_weights(network, row, l_rate):\n",
    "    \n",
    "    # por cada capa de la red\n",
    "    for i in range(len(network)):\n",
    "        \n",
    "        #extraer la clasificación real del vector de entrada. \n",
    "        inputs = row[:-1]\n",
    "        \n",
    "        #las salidas ahora son las entradas de la siguiente capa\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    " \n",
    "        layer = network[i]\n",
    "        for neuron in layer:\n",
    "            for j in range(len(inputs)):\n",
    "                \n",
    "                # por cada neurona y cada una de sus entradas\n",
    "                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "            \n",
    "            #actualización del bias\n",
    "            neuron['weights'][-1] += l_rate * neuron['delta']\n",
    "           \n",
    "\n",
    "       \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenar la red con Gradiente Descendiente estocástico**\n",
    "\n",
    "* una característica diferente a Gradiente descendiente normal, es que por cada iteación, utiliza un vector de entrada diferente para actualizar los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        \n",
    "        #por cada vector en el conjunto de entrenamiento.\n",
    "        for row in train:\n",
    "            \n",
    "            # se calcular la salida de un elemento del vector\n",
    "            outputs = forward_propagate(network, row)\n",
    "            \n",
    "            #preparamos con ceros\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            \n",
    "            #la posición row[-1] \\in {0,1} tendrá un 1\n",
    "            expected[int(row[-1])] = 1\n",
    "            \n",
    "            #sumamos cada error en cada dimensión diferente\n",
    "            \n",
    "       #     sum_error += sum([(expected[i]-outputs[i] )**2 for i in range(len(expected))])\n",
    "            \n",
    "            zi = expected[1]\n",
    "            zi_e = outputs[1]\n",
    "            \n",
    "            #aquí el error reportado es la suma log verosimilitud , queremos que sea el máximo\n",
    "            #sum_error += zi*math.log(zi_e)+(1-zi)*math.log(1-zi_e)\n",
    "            sum_error += zi*math.log(zi_e)+(1-zi)*math.log(1-zi_e)\n",
    "        \n",
    "      \n",
    "            #propagamos hacia atrás \n",
    "            #el error generado por la diferencia de el valor esperado y el valor generado por la red\n",
    "            # se reajusta la red para predecir mejor el valor esperado\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = [[ 0.        , 43.57879291,  0.        ],\n",
    "       [ 1.        , 38.25686159,  0.        ],\n",
    "       [ 2.        , 33.65222425,  0.        ],\n",
    "       [ 3.        , 35.58326609,  0.        ],\n",
    "       [ 4.        , 34.71588722,  0.        ],\n",
    "       [ 5.        , 32.38702072,  0.        ],\n",
    "       [ 6.        , 28.39419039,  0.        ],\n",
    "       [ 7.        , 20.20082333,  0.        ],\n",
    "       [ 8.        , 24.19586975,  0.        ],\n",
    "       [ 9.        , 18.48536939,  0.        ],\n",
    "       [10.        , 19.43098795,  0.        ],\n",
    "       [11.        ,  9.78931084,  0.        ],\n",
    "       [12.        , 14.4403072 ,  0.        ],\n",
    "       [13.        ,  8.95888303,  0.        ],\n",
    "       [14.        ,  7.17704765,  0.        ],\n",
    "       [15.        ,  9.57779397,  0.        ],\n",
    "       [16.        ,  7.58424501,  0.        ],\n",
    "       [17.        ,  8.9341588 ,  0.        ],\n",
    "       [18.        ,  3.13378008,  0.        ],\n",
    "       [19.        ,  9.23532406,  0.        ],\n",
    "       [20.        ,  6.43370902,  0.        ],\n",
    "       [21.        ,  6.67961846,  0.        ],\n",
    "       [22.        ,  5.15107388,  0.        ],\n",
    "       [23.        ,  3.13252828,  0.        ],\n",
    "       [24.        ,  9.40036651,  0.        ],\n",
    "       [25.        ,  8.96646931,  0.        ],\n",
    "       [26.        , 12.97187713,  0.        ],\n",
    "       [27.        ,  6.17097537,  0.        ],\n",
    "       [28.        , 14.94380716,  0.        ],\n",
    "       [29.        , 15.78038035,  0.        ],\n",
    "       [30.        , 13.44006058,  0.        ],\n",
    "       [31.        , 12.38640541,  0.        ],\n",
    "       [32.        , 18.24681531,  0.        ],\n",
    "       [33.        , 24.89568658,  0.        ],\n",
    "       [34.        , 20.9740082 ,  0.        ],\n",
    "       [35.        , 29.60592301,  0.        ],\n",
    "       [36.        , 28.15828701,  0.        ],\n",
    "       [37.        , 36.2793585 ,  0.        ],\n",
    "       [38.        , 35.14373666,  0.        ],\n",
    "       [39.        , 45.91909167,  0.        ],\n",
    "       [ 0.        , 72.99963497,  1.        ],\n",
    "       [ 1.        , 66.25249531,  1.        ],\n",
    "       [ 2.        , 69.47862325,  1.        ],\n",
    "       [ 3.        , 68.12423544,  1.        ],\n",
    "       [ 4.        , 58.18406218,  1.        ],\n",
    "       [ 5.        , 59.71572434,  1.        ],\n",
    "       [ 6.        , 56.45457802,  1.        ],\n",
    "       [ 7.        , 52.4068255 ,  1.        ],\n",
    "       [ 8.        , 47.24274882,  1.        ],\n",
    "       [ 9.        , 43.36311311,  1.        ],\n",
    "       [10.        , 44.07483255,  1.        ],\n",
    "       [11.        , 39.85302512,  1.        ],\n",
    "       [12.        , 44.01192218,  1.        ],\n",
    "       [13.        , 41.07318483,  1.        ],\n",
    "       [14.        , 33.8127034 ,  1.        ],\n",
    "       [15.        , 33.21045858,  1.        ],\n",
    "       [16.        , 37.15741812,  1.        ],\n",
    "       [17.        , 31.73730861,  1.        ],\n",
    "       [18.        , 34.83305033,  1.        ],\n",
    "       [19.        , 39.87419754,  1.        ],\n",
    "       [20.        , 31.48844934,  1.        ],\n",
    "       [21.        , 35.0882841 ,  1.        ],\n",
    "       [22.        , 39.71262275,  1.        ],\n",
    "       [23.        , 31.62777132,  1.        ],\n",
    "       [24.        , 40.68066481,  1.        ],\n",
    "       [25.        , 36.14619892,  1.        ],\n",
    "       [26.        , 38.39007043,  1.        ],\n",
    "       [27.        , 35.30625817,  1.        ],\n",
    "       [28.        , 38.9855814 ,  1.        ],\n",
    "       [29.        , 44.46375169,  1.        ],\n",
    "       [30.        , 42.9567545 ,  1.        ],\n",
    "       [31.        , 43.13876601,  1.        ],\n",
    "       [32.        , 46.36785753,  1.        ],\n",
    "       [33.        , 53.20209487,  1.        ],\n",
    "       [34.        , 54.57671019,  1.        ],\n",
    "       [35.        , 61.72180758,  1.        ],\n",
    "       [36.        , 56.20328364,  1.        ],\n",
    "       [37.        , 60.75140654,  1.        ],\n",
    "       [38.        , 62.61155513,  1.        ],\n",
    "       [39.        , 67.27858905,  1.        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.59697275, 0.        ],\n",
       "       [0.02564103, 0.52406922, 0.        ],\n",
       "       [0.05128205, 0.46099168, 0.        ],\n",
       "       [0.07692308, 0.48744444, 0.        ],\n",
       "       [0.1025641 , 0.47556248, 0.        ],\n",
       "       [0.12820513, 0.44366004, 0.        ],\n",
       "       [0.15384615, 0.38896346, 0.        ],\n",
       "       [0.17948718, 0.27672499, 0.        ],\n",
       "       [0.20512821, 0.33145193, 0.        ],\n",
       "       [0.23076923, 0.2532255 , 0.        ],\n",
       "       [0.25641026, 0.26617925, 0.        ],\n",
       "       [0.28205128, 0.13410082, 0.        ],\n",
       "       [0.30769231, 0.19781342, 0.        ],\n",
       "       [0.33333333, 0.12272504, 0.        ],\n",
       "       [0.35897436, 0.09831621, 0.        ],\n",
       "       [0.38461538, 0.13120331, 0.        ],\n",
       "       [0.41025641, 0.10389429, 0.        ],\n",
       "       [0.43589744, 0.12238635, 0.        ],\n",
       "       [0.46153846, 0.04292871, 0.        ],\n",
       "       [0.48717949, 0.12651192, 0.        ],\n",
       "       [0.51282051, 0.08813344, 0.        ],\n",
       "       [0.53846154, 0.09150208, 0.        ],\n",
       "       [0.56410256, 0.07056301, 0.        ],\n",
       "       [0.58974359, 0.04291156, 0.        ],\n",
       "       [0.61538462, 0.12877279, 0.        ],\n",
       "       [0.64102564, 0.12282896, 0.        ],\n",
       "       [0.66666667, 0.17769784, 0.        ],\n",
       "       [0.69230769, 0.08453433, 0.        ],\n",
       "       [0.71794872, 0.20471071, 0.        ],\n",
       "       [0.74358974, 0.21617067, 0.        ],\n",
       "       [0.76923077, 0.18411134, 0.        ],\n",
       "       [0.79487179, 0.16967763, 0.        ],\n",
       "       [0.82051282, 0.24995762, 0.        ],\n",
       "       [0.84615385, 0.34103851, 0.        ],\n",
       "       [0.87179487, 0.28731662, 0.        ],\n",
       "       [0.8974359 , 0.40556262, 0.        ],\n",
       "       [0.92307692, 0.38573189, 0.        ],\n",
       "       [0.94871795, 0.49698   , 0.        ],\n",
       "       [0.97435897, 0.48142346, 0.        ],\n",
       "       [1.        , 0.6290318 , 0.        ],\n",
       "       [0.        , 1.        , 1.        ],\n",
       "       [0.02564103, 0.90757297, 1.        ],\n",
       "       [0.05128205, 0.95176672, 1.        ],\n",
       "       [0.07692308, 0.93321337, 1.        ],\n",
       "       [0.1025641 , 0.79704593, 1.        ],\n",
       "       [0.12820513, 0.81802771, 1.        ],\n",
       "       [0.15384615, 0.77335425, 1.        ],\n",
       "       [0.17948718, 0.71790531, 1.        ],\n",
       "       [0.20512821, 0.64716418, 1.        ],\n",
       "       [0.23076923, 0.59401822, 1.        ],\n",
       "       [0.25641026, 0.60376785, 1.        ],\n",
       "       [0.28205128, 0.54593458, 1.        ],\n",
       "       [0.30769231, 0.60290606, 1.        ],\n",
       "       [0.33333333, 0.56264918, 1.        ],\n",
       "       [0.35897436, 0.46319003, 1.        ],\n",
       "       [0.38461538, 0.45494006, 1.        ],\n",
       "       [0.41025641, 0.50900827, 1.        ],\n",
       "       [0.43589744, 0.43475983, 1.        ],\n",
       "       [0.46153846, 0.47716746, 1.        ],\n",
       "       [0.48717949, 0.54622462, 1.        ],\n",
       "       [0.51282051, 0.43135078, 1.        ],\n",
       "       [0.53846154, 0.48066383, 1.        ],\n",
       "       [0.56410256, 0.54401125, 1.        ],\n",
       "       [0.58974359, 0.43325931, 1.        ],\n",
       "       [0.61538462, 0.55727217, 1.        ],\n",
       "       [0.64102564, 0.49515589, 1.        ],\n",
       "       [0.66666667, 0.52589401, 1.        ],\n",
       "       [0.69230769, 0.48364979, 1.        ],\n",
       "       [0.71794872, 0.53405173, 1.        ],\n",
       "       [0.74358974, 0.60909553, 1.        ],\n",
       "       [0.76923077, 0.58845163, 1.        ],\n",
       "       [0.79487179, 0.59094496, 1.        ],\n",
       "       [0.82051282, 0.63517931, 1.        ],\n",
       "       [0.84615385, 0.72879946, 1.        ],\n",
       "       [0.87179487, 0.74762991, 1.        ],\n",
       "       [0.8974359 , 0.84550844, 1.        ],\n",
       "       [0.92307692, 0.76991184, 1.        ],\n",
       "       [0.94871795, 0.83221521, 1.        ],\n",
       "       [0.97435897, 0.85769682, 1.        ],\n",
       "       [1.        , 0.92162912, 1.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.array(dataset)\n",
    "\n",
    "dataset[:,0] = dataset[:,0]/max(dataset[:,0])\n",
    "dataset[:,1] = dataset[:,1]/max(dataset[:,1])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  2\n",
      "outputs:  2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'update_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5ecba10c152f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-46c3941400f1>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(network, train, l_rate, n_epoch, n_outputs)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# se reajusta la red para predecir mejor el valor esperado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mbackward_propagate_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>epoch=%d, lrate=%.3f, error=%.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'update_weights' is not defined"
     ]
    }
   ],
   "source": [
    "n_inputs = len(dataset[0]) - 1\n",
    "print(\"inputs: \", n_inputs)\n",
    "\n",
    "#total possible number of output values\n",
    "n_outputs = len(set([ int(row[-1]) for row in dataset]))\n",
    "print(\"outputs: \", n_outputs)\n",
    "\n",
    "network = initialize_network(n_inputs, 4, n_outputs)\n",
    "train_network(network, dataset, 0.01, 10000, n_outputs)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expectation: 0.0 reality 1\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 1\n",
      "expectation: 0.0 reality 0\n",
      "expectation: 0.0 reality 1\n",
      "expectation: 0.0 reality 1\n",
      "expectation: 0.0 reality 1\n",
      "expectation: 0.0 reality 1\n",
      "expectation: 0.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 0\n",
      "expectation: 1.0 reality 0\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 0\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n",
      "expectation: 1.0 reality 1\n"
     ]
    }
   ],
   "source": [
    "e = 0\n",
    "for x in dataset:\n",
    "    \n",
    "    y = forward_propagate(network, x[:2])\n",
    "    print(\"expectation:\",x[-1],\"reality\",1*((y[-1])>0.5))\n",
    "    \n",
    "    e+= (x[-1]- 1*((y[-1])>0.5))**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurna no. 0\n",
      "-0.524819613827942\n",
      "neurna no. 1\n",
      "-0.06621286561628859\n",
      "neurna no. 2\n",
      "-0.4060077630258488\n",
      "neurna no. 3\n",
      "2.1053948455209897\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "i=0\n",
    "\n",
    "n_neuronas = len(network[i])\n",
    "\n",
    "for j in range(n_neuronas):\n",
    "    print(\"neurna no.\",j)\n",
    "    error = 0\n",
    "\n",
    "    for neuron in network[i+1]:\n",
    "   #     print(\"layer:\",neuron)\n",
    "   #     print(\"weights\",i+1,j,neuron[\"weights\"][j])\n",
    "        error += neuron[\"weights\"][j]*neuron['delta']\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
